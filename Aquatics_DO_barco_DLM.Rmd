---
title: "Aquatucs_DO_barco"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read in packages
```{r}
#remotes::install_github("eco4cast/neon4cast")
library(lubridate)
library(neonstore)
library(modelr)
library(coda)
library(daymetr)
library(tidyverse)
library(tidybayes)
library(nimble)
library(imputeTS)
library(neon4cast)
Sys.setenv("NEONSTORE_HOME" = "neon_store/")
if(dir.exists("neon_store/")){
  dir.create("neon_store/")
}
```


read in EFI forecasty challenge data
```{r}
daily_data <- readr::read_csv("https://data.ecoforecast.org/targets/aquatics/aquatics-targets.csv.gz") %>% filter(siteID == "BARC") %>% arrange(-desc(time))
```
Download NEON air temp data
```{r}
focal_sites <- c("BARC")
#neonstore::neon_download("DP1.20046.001", site =  focal_sites, type="basic") #Air Temp on Water Above Buoy
air_temp <- neonstore::neon_read("RHbuoy_30min", site = focal_sites)
```
Summarize air temp data to daily and clean up
```{r}

daily_air_temp <- air_temp %>% 
  select(siteID, startDateTime, tempRHMean, tempRHMinimum, tempRHMaximum, tempRHVariance,tempRHExpUncert, tempRHStdErMean, tempRHFinalQF) %>%
  mutate(time = as.Date(startDateTime)) %>% 
  filter(tempRHFinalQF == 0) %>%
arrange(-desc(time)) %>%
  group_by(siteID, time) %>% 
  summarize(air_temp = mean(tempRHMean, na.rm = TRUE),
                   tempRHExpUncert = mean(tempRHExpUncert, na.rm = TRUE),
                   .groups = "drop")
```


Load NOAA met forecast data
```{r}
aq_sites <- unique(daily_data$siteID)
download_noaa(siteID = aq_sites, interval = "6hr", date = "2021-03-01", cycle = "00")
noaa_fc <- stack_noaa()
noaa_fc

#Tidy up forecast data
ens_num = as.numeric(str_sub(noaa_fc$ensemble,4,5))
noaa_fc = noaa_fc %>% mutate(ensemble = ens_num)
noaa_fc = noaa_fc %>% mutate(startDate = as.POSIXct(startDate)) %>%
  mutate(DateTime = startDate + dhours(noaa_fc$time)) %>%
  mutate(air_temperature_C = air_temperature - 273.15) %>% 
  group_by(date(DateTime),ensemble) %>%
  mutate(time = date(DateTime)) %>%
  mutate(daily_temp = mean(air_temperature_C)) %>%
  ungroup(DateTime,ensemble)

noaa_fc %>% ggplot() +
  geom_path(aes(x=DateTime,y=daily_temp,colour=as.factor(ensemble)))
  
```



Visualize, interpolate, and fill in missing days
```{r}
#adding missing dates to interpolate 
dates_for_modelfit <- data.frame( time = seq(as.Date("2019-01-01"), as.Date("2021-03-07"), by="days"))

#merge two data frame best on date so that dates w/out NAs are now in data frame just NA 
daily_data <- left_join(dates_for_modelfit, daily_data, by = "time") 
  daily_data <- left_join(x=daily_data,y=daily_air_temp, by = c("time","siteID")) %>% #add in air temp column
  mutate(siteID = "BARC")

#interpolate temp data
daily_data$temperature <- na_interpolation(daily_data$temperature)
daily_data$air_temp <- na_interpolation(daily_data$air_temp)
daily_data$temperature_sd <- na_interpolation(daily_data$temperature_sd)
daily_data$tempRHExpUncert <- na_interpolation(daily_data$tempRHExpUncert)
daily_data$oxygen_sd <- na_interpolation(daily_data$oxygen_sd)

daily_data_forecast <- daily_data  %>% filter(time <= "2021-02-28")
daily_data_full <- daily_data

daily_data_forecast %>%
  ggplot(aes(x = time, y = air_temp)) +
  geom_point() +
  facet_wrap(~siteID) +
  labs(x = "Date")
```


DLM model
```{r}
Temp <- daily_data_forecast$air_temp
DO <- daily_data_forecast$oxygen
sd_obs <- daily_data_forecast$oxygen_sd


DLM <- nimbleCode({
   #### Priors
 x[1] ~ dnorm(x_ic, sd = sd_ic)
 sd_add ~ dunif(0, 100)
 beta_0 ~ dnorm(1.11,sd=0.01) #dnorm(0, sd=5)
 beta_1 ~ dnorm(0.53,sd=0.1) #dnorm(0, sd=5)
 beta_x ~ dnorm(1.73,sd=0.1) #dnorm(0, sd=5)
 
   #### Process Model
 for(t in 2:n){
   pred[t] <- x[t-1] +  beta_0 + beta_1 * Temp[t] - beta_x * x[t-1]
   x[t] ~ dnorm(pred[t], sd = sd_add)
 }
 #### Data Model
 for(t in 1:n){
   y[t] ~ dnorm(x[t], sd = sd_obs[t])
 }
})
constants <- list(n = length(DO),
                 x_ic = 7.3,
                 sd_ic = 0.1,
                 sd_obs = sd_obs,
                 Temp = Temp)

data <- list(y = DO)
nchain = 3
inits <- list()
for(i in 1:nchain){
 y.samp = sample(DO, length(DO), replace = TRUE)
 inits[[i]] <- list(sd_add = sd(diff(na.omit(y.samp))),
                    x = DO,
                    beta_0 = rnorm(1,1.1,0.1), #2,0.5),
                    beta_1 = rnorm(1,0.5,0.1), #-0.03,0.1),
                    beta_x = rnorm(1,1.7,0.1) #-0.15,0.1)
                    )
}
nimble_out <- nimbleMCMC(code = DLM,
                        data = data,
                        inits = inits,
                        constants = constants,
                        monitors = c("sd_add",
                                     "beta_0",
                                     "beta_1",
                                     "beta_x",
                                      "x",
                                      "y"),
                        niter = 15000,
                        nchains = 3,
                        samplesAsCodaMCMC = TRUE)
#plot(nimble_out)
plot(nimble_out[, c("sd_add")])
gelman.diag(nimble_out[, c("sd_add")])  ## determine convergence

## burn-in
burnin <- 5000                               
nimble_burn <- window(nimble_out, start = burnin)
plot(nimble_burn[, c("sd_add")])
plot(nimble_burn[, c("beta_0")])
plot(nimble_burn[, c("beta_1")])
plot(nimble_burn[, c("beta_x")])
effectiveSize(nimble_burn[, c("sd_add")])
gelman.diag(nimble_burn[, c("sd_add")])  ## determine convergence

chain_dlm <- nimble_burn %>%
  spread_draws(y[day],x[day],sd_add) %>%
  mutate(y = y,
         x = x)
chain_dlm %>%
  summarize(sd_add = mean(sd_add))
```

Plot nimble DLM
```{r}
DO_pred <- chain_dlm %>% group_by(day) %>% 
            summarise(mean = mean(x),
            upper = quantile(x, 0.975),
            lower = quantile(x, 0.025),.groups = "drop") %>% 
             mutate(date = daily_data_forecast$time) 
  ggplot(data= DO_pred, aes(x = date, y = mean)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2, color = "lightblue", fill = "lightblue") +
  geom_point(data = daily_data_forecast, aes(x = time, y = oxygen), shape=21, color="darkblue",size=2) + 
    scale_shape_identity() + labs(x = "Date", y = "DO (mg/L)", title = "Nimble DLM") 
```


Create forecast using forecasted NOAA temp
```{r}
#sample from posterior   
params <- nimble_burn %>%
  tidybayes::spread_draws(beta_0, beta_1, beta_x, sd_add)
IC <- chain_dlm %>% select(day,.chain,.iteration,.draw,x) 
IC <- IC %>% filter(day==790) 
IC <- as.matrix(IC)
params <- as.matrix(params)

### settings
Nmc <- 1000                  ## set number of Monte Carlo draws
time1 <- nrow(DO_pred)       ## calibration period
time2 <- 7                   ## forecast period
time_full <- time1 + time2   ## total time

#need to use forecasted NOAA temp
#Temp <- noaa_fc #edit this to include the 7 day forecasted temp

forecastDO <- function(IC, beta_0, beta_1,beta_x, sd_add, n){
  x <- matrix(NA, n, time2)  ## storage
  x[,1] <- IC                ## initialize
  for(i in 1:n){
    for(t in 2:time2){
      pred <- x[t-1] +  beta_0 + beta_1 * Temp[t] - beta_x * x[t-1]
      x[i,t] <- rnorm(1,pred,sd=sd_add[i])
    }
  }
  return(x)
}

# Sample parameters
prow <- sample.int(nrow(params),Nmc,replace=TRUE)
## initial conditions
prow_IC <- sample.int(nrow(IC),Nmc,replace=TRUE)

DO.det <- forecastDO(IC = IC[prow_IC,"x"],
                   beta_0 = params[prow,"beta_0"],
                   beta_1 = params[prow,"beta_1"],
                   beta_x = params[prow,"beta_x"],
                   sd_add = params[prow,"sd_add"],  ## process error
                   n = Nmc)

ci <- apply(DO.det, 2, quantile, c(0.025, 0.5, 0.975)) 
ci <- t(ci)
ci <- as.data.frame(ci) %>% mutate(time = seq(as.Date("2021-03-01"), as.Date("2021-03-07"),1))
colnames(ci) <- c("lower","mean","upper","date")

#drop col for merging
DO_pred <- DO_pred %>% select(-day)

#merge dataframes
DO_final <- rbind(DO_pred,ci)

#plot forecast
  ggplot() +
  xlim(c(as.Date("2021-02-01"),as.Date("2021-03-07"))) +
  geom_line(data= DO_final, aes(x = date, y = mean)) + 
  geom_ribbon(data= DO_final, aes(x = date, ymin = lower, ymax = upper), alpha = 0.2, color = "lightblue", fill = "lightblue") +
  geom_point(data = daily_data_forecast, aes(x = time, y = oxygen), shape=21, color="darkblue",size=1.5) + 
    scale_shape_identity() + labs(x = "Date", y = "DO (mg/L)", title = "DO model") 
```

Data assimilation w/ particle filter
```{r}
y <- daily_data_full$oxygen
y[1:790] <- NA


sd_data <- 200

num_particles <- 100
nt <- length(y)

sd_add <- 0.2
sd_obs <- 400 

#paramerer values
beta_0 <- mean(params[,"beta_0"])
beta_1 <- mean(params[,"beta_1"])
beta_x <- mean(params[,"beta_x"])
sd_add <- mean(params[,"sd_add"])

#pull oxygen for last time step
oxygen_IC <- IC[,"x"]

sd_init <- dnorm(oxygen_IC, mean=mean(oxygen_IC),sd=sd(oxygen_IC))

x <- array(NA, dim = c(nt, num_particles))
x[1,] <- rnorm(num_particles, mean = mean(oxygen_IC), sd = sd(oxygen_IC))

### resampling bootstrap particle filter
for(t in 2:nt){
  
  ## forward step
  for(m in 1:num_particles){
    
    pred <- x[t-1] +  beta_0 + beta_1 * Temp[t] - beta_x * x[t-1]
    
    x[t,m] <- pred + rnorm(1, mean = 0, sd = sd_add)   
  }
 
  ## analysis step
  if(!is.na(y[t])){
    
    ## calculate Likelihood (weights)
    wt <- dnorm(y[t], mean =  x[t, ], sd = sd_obs)    ## calculate likelihood (weight)
    
    ## resample ensemble members in proportion to their weight
    resample_index <- sample(1:num_particles, num_particles, replace = TRUE, prob = wt) 

     x[t, ] <-  x[t, resample_index] ## update state
  }
}
```

